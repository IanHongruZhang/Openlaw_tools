{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### 第一模块(导入包模块：必须运行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 引入所有包,如果缺少某个包，包的名字附于之后\n",
    "import numpy as np\n",
    "# numpy\n",
    "\n",
    "import pandas as pd\n",
    "# pandas\n",
    "\n",
    "import requests\n",
    "# requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "# BeautifulSoup\n",
    "\n",
    "import re\n",
    "# re\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "# fake-useragent\n",
    "\n",
    "import json\n",
    "# json\n",
    "\n",
    "import time\n",
    "# time\n",
    "\n",
    "import random\n",
    "# random\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# selenium\n",
    "\n",
    "from PIL import Image,ImageEnhance\n",
    "# PIL\n",
    "\n",
    "import hashlib\n",
    "# hashlib\n",
    "\n",
    "from collections import Counter\n",
    "# collections\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "# gensim \n",
    "\n",
    "import codecs, sys\n",
    "# codecs\n",
    "\n",
    "import os\n",
    "# os\n",
    "\n",
    "import time\n",
    "#time\n",
    "\n",
    "import shutil\n",
    "# shutil\n",
    "\n",
    "import jieba\n",
    "# jieba\n",
    "\n",
    "from pyhanlp import *\n",
    "# pyhanlp，注意hanlp需要java的工具\n",
    "\n",
    "import jpype\n",
    "# jpype\n",
    "\n",
    "import tensorflow as tf\n",
    "# tensorflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import feature_extraction  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# sklearn\n",
    "\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "# pdfminer3k\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "# tk文件导入模块\n",
    "\n",
    "from tqdm import tqdm_notebook, _tqdm_notebook\n",
    "from tqdm._tqdm_notebook import tnrange\n",
    "_tqdm_notebook.tqdm_notebook.pandas()\n",
    "# 进度条部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第二模块(文件处理模块：必须运行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_table(root):\n",
    "    \"\"\"\n",
    "    return table\"选中的表格\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root.filename = filedialog.askopenfilename(filetypes=((\"xlsx\", \"*.xlsx\"),(\"xlsx\", \"*.xlsx\")))        \n",
    "        if \".xlsx\" in root.filename:\n",
    "            ### 该目录下有该文件\n",
    "            table = pd.read_excel(root.filename)\n",
    "            root.destroy()\n",
    "            return table\n",
    "    except Exception as e:\n",
    "        root.destroy()\n",
    "        print(\"导入错误\")\n",
    "\n",
    "def remote_select():\n",
    "    print(\"以下文件可以调用，需要分析哪个文件？\")\n",
    "    print(\"-------------------------------------\")\n",
    "    index = 0\n",
    "    list_item_temp = []\n",
    "    for item in os.listdir():\n",
    "        if \".xlsx\" in item:\n",
    "            index += 1\n",
    "            print(\"[\" + str(index) + \"] \" + item)\n",
    "            list_item_temp.append(item)\n",
    "    try:\n",
    "        bash_pos = \"/Users/dfuser/Desktop/目标文书目录/\"\n",
    "        file_code = int(input(\"需要导入哪个文件？(输入[]中的序号)\"))\n",
    "        final_pos = bash_pos + str(list_item_temp[file_code-1])\n",
    "        table_ = pd.read_excel(final_pos)\n",
    "        return table_\n",
    "        print(\"表格导入成功，以下是表格预览\")\n",
    "        print(\"----------------------------\")\n",
    "    except Exception as e:\n",
    "        print(\"导入错误\")\n",
    "\n",
    "def save_model(table):\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"以下为表格的预览:\")\n",
    "    print(table.head())\n",
    "    flag = input(\"是否需要保存该词频表？(输入Y/N):\")\n",
    "    try:\n",
    "        if flag == \"Y\":\n",
    "            save_file_name = input(\"请输入该词频表格的名称(不用加.xlsx):\")\n",
    "            save_file_name_xlsx = save_file_name + \".xlsx\"\n",
    "            table.to_excel(save_file_name_xlsx)\n",
    "            print(\"存储完毕\")\n",
    "        else:\n",
    "            print(\"未能存储\")\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第三模块(基于hanlp的绝对词频统计:必须运行)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# 绝对词频统计\n",
    "pattern_word = re.compile(r\".*?\\\\\")\n",
    "pattern_nature = re.compile(r\"\\\\.*\")\n",
    "\n",
    "list_useful_words,list_natures = [],[]\n",
    "def segments(article,stopwords):\n",
    "    \"\"\"\n",
    "    param article:每篇文章\n",
    "    param stopwords:停用词列表\n",
    "    return list_articles:每篇文章的分词\n",
    "    \"\"\"\n",
    "    for item in HanLP.segment(article):\n",
    "        try:\n",
    "            item_word = ('{}\\{}'.format(item.word, item.nature))\n",
    "            word = re.search(pattern_word,item_word).group()\n",
    "            nature = re.search(pattern_nature,item_word).group()\n",
    "            word_clean = word.strip(\"\\\\\")\n",
    "            nature_clean = nature.strip(\"\\\\\")\n",
    "            if word_clean not in list_stopwords:\n",
    "                list_useful_words.append(word_clean)\n",
    "                list_natures.append(nature_clean)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return list_useful_words,list_natures\n",
    "\n",
    "def DF(list_useful_words,list_natures):\n",
    "    \"\"\"\n",
    "    param list_useful_words:清洗后得到的词表\n",
    "    param list_natures:清洗后词性的词性表\n",
    "    return table_test_3:\n",
    "    \"\"\"\n",
    "    table_test = pd.DataFrame([list_useful_words,list_natures]).T\n",
    "    table_test.columns = [\"word\",\"nature\"]\n",
    "    \n",
    "    ### 只提取名词和动词！！！！！！！！\n",
    "    table_test_2 = table_test[table_test[\"nature\"].isin([\"n\",\"v\"])]\n",
    "    table_test_3 = table_test_2.groupby(\"word\").count().sort_values([\"nature\"],ascending = False)\n",
    "    return table_test_3\n",
    "\n",
    "def main_word_freqs(corpus,list_stopwords):\n",
    "    \"\"\"\n",
    "    param corpus:每个的文本\n",
    "    param list_stopwords:\n",
    "    return list_articles:每篇关键词的频率\n",
    "    \"\"\"\n",
    "    index = 0\n",
    "    for article in tqdm_notebook(corpus,desc = \"处理进度\"):\n",
    "        try:\n",
    "            #print(article)\n",
    "            list_useful_words,list_natures = segments(article,list_stopwords)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    table = DF(list_useful_words,list_natures)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第四模块(控制部分!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是在本机上操作？还是远程操作？(1:本机操作,2:远程操作)2\n",
      "以下文件可以调用，需要分析哪个文件？\n",
      "-------------------------------------\n",
      "[1] 夫妻债务 - 原表.xlsx\n",
      "[2] ex1.xlsx\n",
      "[3] 校园暴力 - 结构化重构.xlsx\n",
      "[4] 校园暴力事件 - 原表.xlsx\n",
      "[5] 正当防卫 - 原表.xlsx\n",
      "[6] 夫妻债务.xlsx\n",
      "[7] .~zhaiwu_regex_filter.xlsx.xlsx\n",
      "[8] 职业打假人 - 原表.xlsx\n",
      "需要导入哪个文件？(输入[]中的序号)1\n",
      "表格中所有的列: Index(['标题', '案号', '案件类型', '庭审程序', '案由', '文书类型', '法院', '判决日期', '原告', '被告',\n",
      "       '第三人', '法官', '审判长', '审判员', '书记员', '头部', '头部2', '当事人', '当事人2', '庭审程序说明',\n",
      "       '庭审程序说明2', '庭审过程', '庭审过程2', '庭审过程3', '庭审过程4', '庭审过程5', '庭审过程6', '法院意见',\n",
      "       '法院意见2', '判决结果', '判决结果2', '庭后告知', '庭后告知2', '结尾', '结尾2', '附录', '附录2'],\n",
      "      dtype='object')\n",
      "请问需要分析哪一列的关键词词频？(输入关键词部分):判决结果\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57710145b0394f79b09d14ca2376b7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='处理进度', max=1153, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------\n",
      "以下为表格的预览:\n",
      "      nature\n",
      "word        \n",
      "诉讼法     1752\n",
      "原审      1530\n",
      "案件      1515\n",
      "利息      1395\n",
      "负担      1330\n",
      "是否需要保存该词频表？(输入Y/N):Y\n",
      "请输入该词频表格的名称(不用加.xlsx):wordfreqs\n",
      "存储完毕\n"
     ]
    }
   ],
   "source": [
    "### 频率部分控制！\n",
    "### 懒得写__main__()了\n",
    "### table_filter_regex.xlsx\n",
    "\n",
    "def run_freqs(corpus,list_stopwords):\n",
    "    corpus = list(filter(lambda x:x!=None,corpus))\n",
    "    table_result = main_word_freqs(corpus,list_stopwords)\n",
    "    return table_result\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    list_stopwords = []\n",
    "    with open(\"stopwords.txt\",\"r\",encoding = \"utf-8\") as f:\n",
    "        for word in f.readlines():\n",
    "            list_stopwords.append(word.strip(\"\\n\"))\n",
    "            \n",
    "    flag_input = int(input(\"你是在本机上操作？还是远程操作？(1:本机操作,2:远程操作)\"))\n",
    "    if flag_input == 1:\n",
    "        root = Tk() # 实例化TKinter窗口\n",
    "        root.withdraw() # 隐藏TKinter窗口\n",
    "        table_ready_to_eat = import_table(root)\n",
    "    elif flag_input == 2:\n",
    "        table_ready_to_eat = remote_select()\n",
    "    else:\n",
    "        logging.error(\"加载错误\")\n",
    "    \n",
    "    print(\"表格中所有的列:\",table_ready_to_eat.columns)\n",
    "    selected_column = input(\"请问需要分析哪一列的关键词词频？(输入关键词部分):\")\n",
    "    corpus = table_ready_to_eat[selected_column]\n",
    "    table_word_freqs = run_freqs(corpus,list_stopwords)\n",
    "    save_model(table_word_freqs)\n",
    "# table_filter_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_word_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
